---
permalink: /
title: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm Ziqi Zhang, currently seeking for a computer science Ph.D candidate opportunity. Meanwhile, I am pursing MicroMasters Program in Statistics and Data Science, **Massachusetts Institute of Technology (MIT)**. 

Previously, I am a Research Assitent (RA) from [School of Engineering](https://engineering.westlake.edu.cn/), **Westlake University**, MiLab. My research includes offline Reinforcement Learning (RL) and Imitation Learning (IL). 

Much more previously, I am a first year Ph.D. candidate at Tsinghua University, majored in Biology.

Feel free to [Email](mailto:stevezhangz@163.com)  me if you would like to collerberate. 

News 
======
- Sep.  2024: One paper has been accepted by **EMNLP'2024**.
- May.  2024: One paper has been accepted by **ICML'2024**.
- Dec.  2023: One paper has been accepted by **AAAI'2024**.
- June. 2022: One paper has been accepted by **CIKM'2022**.

Selected Publications and Pre-prints (* denotes Equal contribution)
======

[1] Ziqi Zhang\*, Jingzehua Xu\*, Zifeng Zhuang, Hongyin Zhang, Jinxin Liu, Donglin wang, Shuai Zhang. [A dynamical clipping approach with task feedback for Proximal Policy Optimization](https://arxiv.org/pdf/2312.07624v3) *Preprint*, arXiv:2312.07624v3. [Code Page](https://github.com/stevezhangzA/pb_ppo)

[2] Ziqi Zhang\*, Xiao Xiong\*, Zifeng Zhuang, Jinxin Liu, Donglin Wang. [Improving Offline-to-Online Reinforcement Learning with Q Conditioned State Entropy Exploration.](https://arxiv.org/abs/2310.19805) *Preprint*, arXiv:2310.19805.

[3] Ziqi Zhang\*, Cunxiang Wang\*, Xiong Xiao, Yue Zhang, Donglin Wang. 2024. [Nash CoT: Multi-Path Inference with Preference Equilibrium.](https://export.arxiv.org/pdf/2407.07099) *Preprint*, arXiv:2407.07099. [Code Page](https://github.com/stevezhangzA/nash-chain-of-thought)

*The 2024 Conference on Empirical Methods in Natural Language Processing* (**EMNLP24 main**)

[4] Zifeng Zhuang, Dengyun Peng, Jinxin Liu, Ziqi Zhang, Donglin Wang. 2024.[Reinformer: Max-Return Sequence Modeling for Offline RL](https://arxiv.org/pdf/2405.08740). *Preprint*, arXiv:2405.08740.

*The 42th International Conference on Machine Learning* (**ICML24 poster**)

[5] Jinxin Liu\*, Ziqi Zhang\*, Zhenyu Wei, Zifeng Zhuang, Yachen Kang, Sibo Gai, Donglin Wang. 2024. [Beyond OOD State Actions: Supported Cross-Domain Offline Reinforcement  earning](https://arxiv.org/pdf/2306.12755). *Preprint*, arXiv:2306.12755.

*The 38th Annual AAAI Conference on Artificial Intelligence* (**AAAI24 poster**) 

[6] Feng Zhao, Ziqi Zhang, Donglin Wang. 2023. [KSG: Knowledge and Skill Graph](https://arxiv.org/pdf/2209.05698). *Preprint*, arXiv:2209.05698.

*Proceedings of the 31st ACM International Conference on Information & Knowledge Management* (**CIKM22 short**)

Research Interests
=====
- How can we improve the data efficiency of RL algorithms, such as enhancing exploration in online settings and stitching in offline settings.
- How to learn a policy beyond the scope of RL.
  
Meanwhile, I am continuously following the advancements in the fields related to RL and decision-making.
